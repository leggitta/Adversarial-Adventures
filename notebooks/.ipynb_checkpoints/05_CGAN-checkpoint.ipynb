{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72739aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import (\n",
    "    ImSet,\n",
    "    ConditionalVariationalAutoEncoder,\n",
    "    ConditionalDiscriminator,\n",
    "    show_tensor\n",
    ")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b508dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0)\n",
    "\n",
    "imset = ImSet()\n",
    "\n",
    "batch_size = len(imset)\n",
    "loader = DataLoader(imset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "cvae = ConditionalVariationalAutoEncoder().to(device)\n",
    "\n",
    "n_trials = 5000\n",
    "n_epochs = 5000\n",
    "\n",
    "model_fname = 'cvae.pth'\n",
    "\n",
    "latent_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = ConditionalDiscriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfun = nn.BCELoss()\n",
    "\n",
    "# create labels\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "real_labels = torch.ones(batch_size, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0bde4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for trial in range(n_trials):\n",
    "    \n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "\n",
    "    real_preds = []\n",
    "    fake_preds = []\n",
    "    \n",
    "    \n",
    "    cvae.load_state_dict(torch.load(model_fname), strict=False)\n",
    "    gen = cvae.dec\n",
    "    dsc.load_state_dict(cvae.enc.state_dict(), strict=False)\n",
    "    \n",
    "    # initialize optimizers\n",
    "    opt_d = torch.optim.Adam(dsc.parameters(), lr=.0002, betas=(.5,.999))\n",
    "    opt_g = torch.optim.Adam(gen.parameters(), lr=.0002, betas=(.5,.999))\n",
    "\n",
    "    # disable early layers\n",
    "    for i, layer in gen.net.named_children():\n",
    "        if int(i) > 13:\n",
    "            layer.requires_grad_ = False\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for (img_fname, img, species_, class_, gender_) in loader:\n",
    "            img = img.to(device)\n",
    "            species_ = species_.to(device)\n",
    "            class_ = class_.to(device)\n",
    "            gender_ = gender_.to(device)\n",
    "            \n",
    "            # forward pass for real\n",
    "            pred_real = dsc(img, species_, class_, gender_)\n",
    "            \n",
    "            d_loss_real = lossfun(pred_real, real_labels)\n",
    "            \n",
    "            # forward pass for fake\n",
    "            fake_data = torch.randn(batch_size, latent_size).to(device)\n",
    "            fake_images = gen(fake_data, species_, class_, gender_)\n",
    "            pred_fake = dsc(fake_images, species_, class_, gender_)\n",
    "            d_loss_fake = lossfun(pred_fake, fake_labels)\n",
    "            \n",
    "            # backprop\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            opt_d.zero_grad()\n",
    "            d_loss.backward()\n",
    "            opt_d.step()\n",
    "            d_losses.append(d_loss.item())\n",
    "            \n",
    "            # train generator\n",
    "            fake_data = torch.randn(batch_size, latent_size).to(device)\n",
    "            fake_images = gen(fake_data, species_, class_, gender_)\n",
    "            pred_fake = dsc(fake_images, species_, class_, gender_)\n",
    "            \n",
    "            # backprop\n",
    "            g_loss = lossfun(pred_fake, real_labels)\n",
    "            opt_g.zero_grad()\n",
    "            g_loss.backward()\n",
    "            opt_g.step()\n",
    "            g_losses.append(g_loss.item())\n",
    "            \n",
    "            real_preds.append(torch.mean((pred_real > 0.5).float()).detach().cpu())\n",
    "            fake_preds.append(torch.mean((pred_fake > 0.5).float()).detach().cpu())\n",
    "            \n",
    "            # visualize output\n",
    "            grid = make_grid(fake_images[:36], nrow=9)\n",
    "\n",
    "            fig = plt.figure(figsize=(15, 12))\n",
    "            gs = GridSpec(5, 1, figure=fig)\n",
    "            ax0 = fig.add_subplot(gs[:3])\n",
    "            ax1 = fig.add_subplot(gs[3])\n",
    "            ax2 = fig.add_subplot(gs[4])\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            show_tensor(grid, ax0)\n",
    "            ax1.plot(g_losses)\n",
    "            ax1.plot(d_losses)\n",
    "            ax2.plot(real_preds)\n",
    "            ax2.plot(fake_preds)\n",
    "            plt.show()\n",
    "    \n",
    "        if epoch % 100 == 0:\n",
    "            fig.savefig(f'CGAN_output/trial_{trial:09}_epoch_{epoch:09}.png')\n",
    "            torch.save(gen.state_dict(), f'CGAN_output/trial_{trial:09}_epoch_{epoch:09}_gen.pth')\n",
    "            torch.save(dsc.state_dict(), f'CGAN_output/trial_{trial:09}_epoch_{epoch:09}_dsc.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca0c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc42b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
