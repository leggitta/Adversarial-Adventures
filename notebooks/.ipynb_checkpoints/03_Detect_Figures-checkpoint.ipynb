{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3945b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from torchvision.transforms import transforms as transforms\n",
    "import os\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc317da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(\n",
    "    pretrained=True, num_keypoints=17\n",
    ")\n",
    "# set the computation device\n",
    "device = torch.device(0)\n",
    "\n",
    "# load the model on to the computation device and set to eval mode\n",
    "model.to(device).eval()\n",
    "\n",
    "# transform to convert the image to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b07e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\t0\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/miniconda3/envs/mytorch/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t8\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/miniconda3/envs/mytorch/lib/python3.9/site-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t8064\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73803/3476592166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# NumPy copy of the image for OpenCV functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# transform the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_files = sorted(glob.glob('../data/raw/*.jpg'))\n",
    "\n",
    "out_dir = '../data/figures/'\n",
    "try:\n",
    "    os.mkdir(out_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for i, fname in enumerate(image_files):\n",
    "    sys.stdout.write('\\r\\t%d\\t' % i)\n",
    "    image = Image.open(fname).convert('RGB')\n",
    "\n",
    "    # NumPy copy of the image for OpenCV functions\n",
    "    img = np.array(image, dtype=np.float32) / 255\n",
    "\n",
    "    # transform the image\n",
    "    image = transform(image)\n",
    "\n",
    "    # add a batch dimension\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    \n",
    "    H, W, _ = img.shape\n",
    "    \n",
    "    boxes = output[0]['boxes'].cpu()\n",
    "    scores = output[0]['scores'].detach().cpu().numpy()\n",
    "    for j, b in enumerate(boxes):\n",
    "        if scores[j] < 0.9:\n",
    "            continue\n",
    "        \n",
    "        x0, y0, x1, y1 = b\n",
    "        w = x1 - x0\n",
    "        h = y1 - y0\n",
    "        \n",
    "        i0 = max(int(x0 - w/4), 0)\n",
    "        i1 = min(int(x1 + w/4), W)\n",
    "        \n",
    "        j0 = max(int(y0 - h/4), 0)\n",
    "        j1 = min(int(y1 + h/4), H)\n",
    "        \n",
    "        im = img[j0:j1, i0:i1]\n",
    "        \n",
    "        outfile = out_dir + fname.split('/')[-1].rstrip('.jpg') + '_%03d' % j + '.pkl'\n",
    "        \n",
    "        # resize to square\n",
    "        img = resize(img, (128, 128))\n",
    "        \n",
    "        with open(outfile, 'wb') as fout:\n",
    "            pickle.dump(im, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6dca951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize(img, (128, 128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab0e566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547, 350, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41be532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
